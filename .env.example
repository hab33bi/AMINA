# AMINA - Environment Variables Template
# Copy this file to .env.local and update with your actual values

# ===========================================
# LM Studio API Configuration
# ===========================================

# Local development (replace with your LM Studio server IP)
REACT_APP_LM_STUDIO_URL=http://192.168.1.174:1234/v1

# Production options (uncomment and use one):
# Option 1: Ngrok tunnel (recommended for quick setup)
# REACT_APP_LM_STUDIO_URL=https://your-unique-id.ngrok-free.app/v1

# Option 2: Port forwarding (requires router configuration)
# REACT_APP_LM_STUDIO_URL=http://your-public-ip:1234/v1

# Option 3: Cloud AI service (alternative)
# REACT_APP_LM_STUDIO_URL=https://api.your-cloud-provider.com/v1

# ===========================================
# Model Configuration
# ===========================================

# Model name (must match your LM Studio loaded model)
REACT_APP_MODEL_NAME=gemma-3-12b

# Alternative models you might use:
# REACT_APP_MODEL_NAME=llama-2-7b-chat
# REACT_APP_MODEL_NAME=mistral-7b-instruct
# REACT_APP_MODEL_NAME=codellama-13b

# ===========================================
# AI Generation Settings
# ===========================================

# Temperature (0.0 = deterministic, 1.0 = creative)
REACT_APP_TEMPERATURE=0.7

# Maximum tokens per response
REACT_APP_MAX_TOKENS=2000

# ===========================================
# App Configuration
# ===========================================

# App branding
REACT_APP_APP_NAME=AMINA
REACT_APP_VERSION=1.0.0

# Features toggles
REACT_APP_ENABLE_IMAGE_UPLOAD=true
REACT_APP_ENABLE_STREAMING=true
REACT_APP_ENABLE_CONVERSATIONS=true

# ===========================================
# Deployment Instructions
# ===========================================

# FOR LOCAL DEVELOPMENT:
# 1. Copy this file to .env.local
# 2. Update REACT_APP_LM_STUDIO_URL with your LM Studio IP
# 3. Run: npm start

# FOR VERCEL DEPLOYMENT:
# 1. Set up ngrok tunnel: ngrok http 1234
# 2. Copy the ngrok URL (e.g., https://abc123.ngrok-free.app)
# 3. In Vercel dashboard → Settings → Environment Variables
# 4. Add: REACT_APP_LM_STUDIO_URL = https://your-ngrok-url.ngrok-free.app/v1
# 5. Redeploy your app

# FOR PORT FORWARDING:
# 1. Configure your router to forward port 1234 to your LM Studio machine
# 2. Find your public IP: https://whatismyipaddress.com
# 3. Set: REACT_APP_LM_STUDIO_URL = http://YOUR_PUBLIC_IP:1234/v1
# 4. Ensure LM Studio allows external connections

# ===========================================
# Security Notes
# ===========================================
# - Never commit .env.local to git
# - Use HTTPS URLs in production when possible
# - Consider authentication for public deployments
# - Monitor usage if exposing your LM Studio publicly
